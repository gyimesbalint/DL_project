{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataimport.ipynb másolata",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyimesbalint/DL_project/blob/main/fitting_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssQLrwJ3b8F1"
      },
      "source": [
        "#Importing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2gR-BhaV0Mr",
        "outputId": "caf71935-15e0-4b9a-e3e7-3756bb817e72"
      },
      "source": [
        "# https://drive.google.com/file/d/1pmNSD1nbYHEAiP065s4akRXHMWFs9Dqw/view?usp=sharing DBpedia train.csv\n",
        "# https://drive.google.com/file/d/1mKededzdbJsWQnwsu-R_WSILYSvNEY7c/view?usp=sharing DBpedia test.csv\n",
        "!pip install gdown\n",
        "!gdown --id 1pmNSD1nbYHEAiP065s4akRXHMWFs9Dqw --output train.csv  #import train.csv from drive\n",
        "!gdown --id 1mKededzdbJsWQnwsu-R_WSILYSvNEY7c --output test.csv   #import test.csv from drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pmNSD1nbYHEAiP065s4akRXHMWFs9Dqw\n",
            "To: /content/train.csv\n",
            "100% 174M/174M [00:01<00:00, 161MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mKededzdbJsWQnwsu-R_WSILYSvNEY7c\n",
            "To: /content/test.csv\n",
            "100% 21.8M/21.8M [00:00<00:00, 133MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7DxLlchmrSG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('train.csv', encoding='utf8',header=None) #read csv to dataframe\n",
        "test_data = pd.read_csv('test.csv', encoding='utf8',header=None)   #read csv to dataframe\n",
        "\n",
        "train_data.where(train_data[0] < 6, inplace = True)  #select first 5 categories\n",
        "train_data = train_data[train_data[0].notnull()]     #remove NaN values\n",
        "\n",
        "test_data.where(test_data[0] < 6, inplace = True)    #select first 5 categories\n",
        "test_data = test_data[test_data[0].notnull()]        #remove NaN values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oC2QSasgcGUv",
        "outputId": "74a2042c-10ff-4bf9-9cc4-adf97c4d5a0c"
      },
      "source": [
        "train_data.sample(5) #sample from train data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>107667</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Ambrose Bebb</td>\n",
              "      <td>William Ambrose Bebb (4 July 1894 – 27 April ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168118</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Malcolm Pearson Baron Pearson of Rannoch</td>\n",
              "      <td>Malcolm Everard MacLaren Pearson Baron Pearso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69230</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Strategic studies</td>\n",
              "      <td>Strategic studies is an interdisciplinary aca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150726</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Atari Bigby</td>\n",
              "      <td>Atari David Bigby (born September 19 1981) is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36600</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Roussel Uclaf</td>\n",
              "      <td>Roussel Uclaf S.A. was the second largest Fre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0  ...                                                  2\n",
              "107667  3.0  ...   William Ambrose Bebb (4 July 1894 – 27 April ...\n",
              "168118  5.0  ...   Malcolm Everard MacLaren Pearson Baron Pearso...\n",
              "69230   2.0  ...   Strategic studies is an interdisciplinary aca...\n",
              "150726  4.0  ...   Atari David Bigby (born September 19 1981) is...\n",
              "36600   1.0  ...   Roussel Uclaf S.A. was the second largest Fre...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LuZIprN5fGcK",
        "outputId": "41134599-fa8d-4c7b-cf61-9406e3b6d0d4"
      },
      "source": [
        "test_data.sample(5) #sample from test data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19736</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Mana Nopnech</td>\n",
              "      <td>Mana Nopnech is a professional footballer fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4020</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Telmex</td>\n",
              "      <td>Telmex is a Mexican telecommunications compan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14279</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Chinami Tokunaga</td>\n",
              "      <td>Chinami Tokunaga (徳永 千奈美 Tokunaga Chinami) (b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21083</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Malcolm Ross (courtier)</td>\n",
              "      <td>Lieutenant-Colonel Sir Walter Hugh Malcolm Ro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16727</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Emanuele Di Zenzo</td>\n",
              "      <td>Emanuele Di Zenzo (born 26 December 1979) is ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0  ...                                                  2\n",
              "19736  4.0  ...   Mana Nopnech is a professional footballer fro...\n",
              "4020   1.0  ...   Telmex is a Mexican telecommunications compan...\n",
              "14279  3.0  ...   Chinami Tokunaga (徳永 千奈美 Tokunaga Chinami) (b...\n",
              "21083  5.0  ...   Lieutenant-Colonel Sir Walter Hugh Malcolm Ro...\n",
              "16727  4.0  ...   Emanuele Di Zenzo (born 26 December 1979) is ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIdmfSJsm4ZN"
      },
      "source": [
        "train_label = pd.to_numeric(train_data.iloc[:,0]) #select labels (int) from train data\n",
        "train_text = train_data.iloc[:,1:3] #select article text from train data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbfQMlpGpJY1"
      },
      "source": [
        "test_label = pd.to_numeric(test_data.iloc[:,0]) #select labels (int) from test data\n",
        "test_text = test_data.iloc[:,1:3] #select article text from train data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqOIQiMFcCKk"
      },
      "source": [
        "#Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGd_NGTLql8R",
        "outputId": "1e77d2ef-7fcd-4a2e-d840-a7661044bfdf"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer #vectorizer for article text data\n",
        "from nltk.corpus import stopwords #stopwords for desktop usage\n",
        "import nltk\n",
        "nltk.download('stopwords') #stopwords for collab notebook"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sdo8wL7CGFM"
      },
      "source": [
        "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), analyzer='word', ngram_range=(1, 1)) #vectorizer for words, removing stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x0-IR01DRW6"
      },
      "source": [
        "test_title = test_text.iloc[:,0] #select titles from test text\n",
        "test_desc = test_text.iloc[:,1]  #select descriptions from test text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuKl7x3U33gu"
      },
      "source": [
        "train_title = train_text.iloc[:,0] #select titles from train text\n",
        "train_desc = train_text.iloc[:,1]  #select descriptions from train text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_3wCcvAmo_N"
      },
      "source": [
        "titles = pd.concat([test_title, train_title]) #concat titles for vectorazition\n",
        "descs = pd.concat([test_desc, train_desc]) #concat descriptions for vectorazition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyFZpmsYEuLP"
      },
      "source": [
        "titles = pd.DataFrame.sparse.from_spmatrix(vectorizer.fit_transform(titles)) #vectorizing test_title and adding it to a dataframe\n",
        "title_feature_names = np.asarray(vectorizer.get_feature_names_out()) #getting all feature names for test_title\n",
        "descs = pd.DataFrame.sparse.from_spmatrix(vectorizer.fit_transform(descs)) #vectorizing test_desc and adding it to a dataframe\n",
        "desc_feature_names = np.asarray(vectorizer.get_feature_names_out()) #getting all feature names for test_desc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5_xy05SwC6g"
      },
      "source": [
        "titles = titles.loc[:, titles.sum(axis=0) > 15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tyVH1MKzbbO",
        "outputId": "a1422bf9-2d33-4456-9173-dce95619cce2"
      },
      "source": [
        "titles.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(225000, 4174)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKD2R761ndPh"
      },
      "source": [
        "#descs = descs.loc[:, descs.sum(axis=0) > 8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK_KvFgDR1si"
      },
      "source": [
        "#descs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H4Pac1xoYgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66238381-5568-4c99-9c01-71a089d9bb07"
      },
      "source": [
        "test_title = titles[0:len(test_title.index)]\n",
        "test_title.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 4174)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqEi2-fBhGtB",
        "outputId": "9f3f284e-98f7-400f-b9f3-58d0e4972907"
      },
      "source": [
        "#First 5 rows and feature names obtained with the vectoritzer\n",
        "print(test_title[0:5])\n",
        "print(title_feature_names[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   302     306     307     308     ...  127536  127570  127803  128028\n",
            "0       0       0       0       0  ...       0       0       0       0\n",
            "1       0       0       0       0  ...       0       0       0       0\n",
            "2       0       0       0       0  ...       0       0       0       0\n",
            "3       0       0       0       0  ...       0       0       0       0\n",
            "4       0       0       0       0  ...       0       0       0       0\n",
            "\n",
            "[5 rows x 4174 columns]\n",
            "['002' '05' '07' '09' '0verflow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5txOGWsp_G_"
      },
      "source": [
        "#test_desc = descs.head(len(test_desc.index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E12HiVEU08Qs"
      },
      "source": [
        "#test_desc.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukBvNK_bpH-J"
      },
      "source": [
        "#First 5 rows and feature names obtained with the vectorizer\n",
        "#print(test_desc[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-54u7V4OFOnh"
      },
      "source": [
        "train_title = titles.tail(len(titles) - len(test_title))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsJ1HLPjycIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe6a8e5f-31a5-4b84-8efe-3485ad238788"
      },
      "source": [
        "train_title.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 4174)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXIH2FymkHOK",
        "outputId": "4f4cfeb2-3386-4a96-bed6-b6d580547a68"
      },
      "source": [
        "#First 5 rows and feature names obtained with the vectoritzer\n",
        "print(train_title[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       302     306     307     308     ...  127536  127570  127803  128028\n",
            "25000       0       0       0       0  ...       0       0       0       0\n",
            "25001       0       0       0       0  ...       0       0       0       0\n",
            "25002       0       0       0       0  ...       0       0       0       0\n",
            "25003       0       0       0       0  ...       0       0       0       0\n",
            "25004       0       0       0       0  ...       0       0       0       0\n",
            "\n",
            "[5 rows x 4174 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKbN2KbbsUqd"
      },
      "source": [
        "#train_desc = descs.tail(len(descs) - len(test_desc.index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFNdC3fUza2X"
      },
      "source": [
        "#train_desc.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmOXEY0fq3Pu"
      },
      "source": [
        "#First 5 rows and feature names obtained with the vectoritzer\n",
        "#print(train_desc[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omfbCxvr-aJl"
      },
      "source": [
        "from scipy.sparse import csr_matrix #for min-max scaling sparse matrices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B3DpLPb7Dku"
      },
      "source": [
        "def normalize(df): #function for min-max scaling of dataframes\n",
        "    result = df.copy()\n",
        "    for feature_name in df.columns:\n",
        "        max_value = csr_matrix(df[feature_name]).max()\n",
        "        min_value = csr_matrix(df[feature_name]).min()\n",
        "        result[feature_name] = (df[feature_name] - min_value) / max((max_value - min_value), 1)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xofqUiCj51N2"
      },
      "source": [
        "test_title = normalize(test_title) #min-max scale test_title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZtMnnUptxIn",
        "outputId": "580887ca-ddda-440f-9152-524beffb7085"
      },
      "source": [
        "print(test_title[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   302     306     307     308     ...  127536  127570  127803  128028\n",
            "0     0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "1     0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "2     0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "3     0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "4     0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "\n",
            "[5 rows x 4174 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v9lEKB951N2"
      },
      "source": [
        "#test_desc = normalize(test_desc) #min-max scale test_desc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH74B7tUtxgF"
      },
      "source": [
        "#print(test_desc[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seP8jG3CB-qB"
      },
      "source": [
        "train_title = normalize(train_title) #min-max scale train_title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z37ue-AbtxyD",
        "outputId": "586eabab-7269-4e4b-984f-6b019a3f3bf6"
      },
      "source": [
        "print(train_title[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       302     306     307     308     ...  127536  127570  127803  128028\n",
            "25000     0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "25001     0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "25002     0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "25003     0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "25004     0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "\n",
            "[5 rows x 4174 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7My4oYrSmLv"
      },
      "source": [
        "#train_desc = normalize(train_desc) #min-max scale train_desc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAJvee20tyUd"
      },
      "source": [
        "#print(train_desc[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SyYggbJorJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096fc5ed-586f-46ff-fc5c-6ec64f5011a8"
      },
      "source": [
        "input_shape = train_title.iloc[0].shape\n",
        "input_shape = (input_shape[0], 1)\n",
        "input_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4174, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsQlbcyBklGw"
      },
      "source": [
        "Our **X** will be the sparse matrices and the feature names from the title and the description, and **Y** will be the labels provided in the csv file.\n",
        "\n",
        "Validation split is obtained later in the model.fit() function from training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in3fW_ywrkWU"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLGT1u65rj22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb7fc033-7e50-4dad-aa66-53c8640de35c"
      },
      "source": [
        "!pip install keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.42.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OYLgAiIe9wE"
      },
      "source": [
        "#from tensorflow.keras.models import Sequential\n",
        "#from tensorflow.keras.layers import Activation, Dense, Flatten, Conv1D, MaxPooling1D, Dropout\n",
        "#from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyAyVcGloOH9"
      },
      "source": [
        "def build_model(hp):\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.Conv1D(\n",
        "        filters=hp.Int('conv_1_filter', min_value=16, max_value=64, step=16),\n",
        "        kernel_size=hp.Choice('conv_1_kernel',values=[3,5]),\n",
        "        activation='relu',\n",
        "        input_shape=input_shape\n",
        "    ),\n",
        "    keras.layers.MaxPooling1D(pool_size=1),\n",
        "    keras.layers.Conv1D(\n",
        "        filters=hp.Int('conv_2_filter', min_value=16, max_value=32, step=16),\n",
        "        kernel_size=hp.Choice('conv_2_kernel',values=[3,5]),\n",
        "        activation='relu'\n",
        "    ),\n",
        "    keras.layers.MaxPooling1D(pool_size=1),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Desne(\n",
        "        units=hp.INt('dense_1_units',min_value=16, max_values=64, step=16),\n",
        "        activation='relu'\n",
        "    ),\n",
        "    keras.layers.Dropout(hp.Float('dropout_1',min_value=0.25,max_value=0.75, step=0.25)),\n",
        "     keras.layers.Desne(5, activation='softmax'),\n",
        "  ])\n",
        "\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBZxmZ1Te9uW"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv1D(32, 3, activation='relu', kernel_initializer='he_normal', input_shape=input_shape))\n",
        "model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
        "model.add(keras.layers.Conv1D(16, 3, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9bmJOY3tn-H",
        "outputId": "dcc9ac4a-5548-4c73-bece-08b50e5159d1"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 4172, 16)          64        \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 1043, 16)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 1041, 16)          784       \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 260, 16)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4160)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                66576     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67,509\n",
            "Trainable params: 67,509\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QW9sGHFtn-I"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "patience=10\n",
        "early_stopping=EarlyStopping(patience=patience, verbose=1)\n",
        "checkpointer=ModelCheckpoint(filepath='model.hdf5', save_best_only=True, verbose=1)\n",
        "tb = TensorBoard(log_dir='logs', histogram_freq=1, write_graph=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Pmi95O9kOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6518ea-2eb1-4b47-9108-d76df009b162"
      },
      "source": [
        "train_title.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 4174)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPdspK-39UvH"
      },
      "source": [
        "\n",
        "\n",
        "partition = {}\n",
        "partition['train']={0:32000}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7fE_7ly9-tf"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, labels, batch_size=4, dim=(4174), n_channels=1,\n",
        "                 n_classes=5, shuffle=True):\n",
        "        #Initialization\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        #Denotes the number of batches per epoch\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #Generate one batch of data\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        # Find list of IDs\n",
        "        #list_IDs_temp = [self.list_IDs.iloc[k] for k in indexes]\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(indexes)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        #Updates indexes after each epoch\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        #Generates data containing batch_size samples\n",
        "        # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "        # Generate data\n",
        "        for i in range(len(list_IDs_temp)):\n",
        "            # Store sample\n",
        "            X[i] = self.list_IDs.iloc[i].to_numpy().reshape(self.dim, self.n_channels)\n",
        "\n",
        "            # Store class\n",
        "            y[i] = self.labels.iloc[i]\n",
        "\n",
        "        return X, to_categorical(y, num_classes=self.n_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2bv5dDMBLmw"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_generator = DataGenerator(train_title, train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI2d4WRAtn-I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "0c780ed2-b6bf-4314-9f90-a4f1b63963fa"
      },
      "source": [
        "network_history = model.fit(train_generator, epochs=30,steps_per_epoch=250, verbose=1, callbacks=[early_stopping, checkpointer, tb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9910WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "250/250 [==============================] - 73s 283ms/step - loss: 0.0893 - accuracy: 0.9910\n",
            "Epoch 2/30\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9970WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "250/250 [==============================] - 70s 281ms/step - loss: 0.0100 - accuracy: 0.9970\n",
            "Epoch 3/30\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "250/250 [==============================] - 72s 286ms/step - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "250/250 [==============================] - ETA: 0s - loss: 2.3655e-04 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "250/250 [==============================] - 71s 284ms/step - loss: 2.3655e-04 - accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "250/250 [==============================] - 71s 283ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "250/250 [==============================] - 71s 284ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "181/250 [====================>.........] - ETA: 20s - loss: 0.0041 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-ad9a2d3f34d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWGJnrXhuf1e"
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"model.hdf5\")\n",
        "test_err = model.evaluate(test_title, test_label)\n",
        "print(\"Teszt hiba:\", test_err[0], \"Teszt pontosság:\", test_err[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ7O1bChuq4l"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, confusion_matrix\n",
        "# először is nyerjük ki a predikciókat (valószínüség és hozzá tartozó pontosságot)\n",
        "y_pred = model.predict(test_title)\n",
        "y_pred = np.argmax(y_pred,1)\n",
        "y_true = np.argmax(y_test,1)\n",
        "\n",
        "print(\"test accuracy: %g\" %(accuracy_score(y_true, y_pred)))\n",
        "print(\"Precision\", precision_score(y_true, y_pred, average=\"macro\"))\n",
        "print(\"Recall\", recall_score(y_true, y_pred, average=\"macro\"))\n",
        "print(\"f1_score\", f1_score(y_true, y_pred, average=\"macro\"))\n",
        "print(\"\\nKonfúziós mátrix: \")\n",
        "conf=confusion_matrix(y_true, y_pred)\n",
        "print(conf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNOZBCYyuumA"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(conf, annot=True, fmt='d', vmax=20) # a vmax paraméterrel állítjuk be, hogy milyen értéktartományban jelenítse meg az adatokat"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}