{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssQLrwJ3b8F1"
   },
   "source": [
    "#Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2gR-BhaV0Mr",
    "outputId": "4504bc89-4e05-459c-8581-6f54d5f5fa49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1pmNSD1nbYHEAiP065s4akRXHMWFs9Dqw\n",
      "To: /content/train.csv\n",
      "100% 174M/174M [00:01<00:00, 127MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1mKededzdbJsWQnwsu-R_WSILYSvNEY7c\n",
      "To: /content/test.csv\n",
      "100% 21.8M/21.8M [00:00<00:00, 133MB/s]\n"
     ]
    }
   ],
   "source": [
    "# https://drive.google.com/file/d/1pmNSD1nbYHEAiP065s4akRXHMWFs9Dqw/view?usp=sharing DBpedia train.csv\n",
    "# https://drive.google.com/file/d/1mKededzdbJsWQnwsu-R_WSILYSvNEY7c/view?usp=sharing DBpedia test.csv\n",
    "!pip install gdown \n",
    "!gdown --id 1pmNSD1nbYHEAiP065s4akRXHMWFs9Dqw --output train.csv  #import train.csv from drive\n",
    "!gdown --id 1mKededzdbJsWQnwsu-R_WSILYSvNEY7c --output test.csv   #import test.csv from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "a7DxLlchmrSG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('train.csv', encoding='utf8',header=None) #read csv to dataframe\n",
    "test_data = pd.read_csv('test.csv', encoding='utf8',header=None)   #read csv to dataframe\n",
    "\n",
    "train_data.where(train_data[0] < 6, inplace = True)  #select first 5 categories\n",
    "train_data = train_data[train_data[0].notnull()]     #remove NaN values\n",
    "\n",
    "test_data.where(test_data[0] < 6, inplace = True)    #select first 5 categories\n",
    "test_data = test_data[test_data[0].notnull()]        #remove NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "oC2QSasgcGUv",
    "outputId": "e8ce6d0a-9523-496f-cea7-ffe60fb38880"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32715</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Inmagine</td>\n",
       "      <td>INMAGINE is a supplier and distributor of Roy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118390</th>\n",
       "      <td>3.0</td>\n",
       "      <td>T. Raumschmiere</td>\n",
       "      <td>Marco Haas (born 1975) is a punk techno DJ kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171652</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Percy Bowers</td>\n",
       "      <td>The Venerable Percy Harris Bowers (1856–1922)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177187</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Benoy Choudhury</td>\n",
       "      <td>Benoy Choudhury (died 2000) was a revolutiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99883</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Kutty (cartoonist)</td>\n",
       "      <td>Puthukkody Kottuthody Sankaran Kutty Nair (4 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                   1  \\\n",
       "32715   1.0            Inmagine   \n",
       "118390  3.0     T. Raumschmiere   \n",
       "171652  5.0        Percy Bowers   \n",
       "177187  5.0     Benoy Choudhury   \n",
       "99883   3.0  Kutty (cartoonist)   \n",
       "\n",
       "                                                        2  \n",
       "32715    INMAGINE is a supplier and distributor of Roy...  \n",
       "118390   Marco Haas (born 1975) is a punk techno DJ kn...  \n",
       "171652   The Venerable Percy Harris Bowers (1856–1922)...  \n",
       "177187   Benoy Choudhury (died 2000) was a revolutiona...  \n",
       "99883    Puthukkody Kottuthody Sankaran Kutty Nair (4 ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(5) #sample from train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "LuZIprN5fGcK",
    "outputId": "eaa4c785-fa0b-4d9f-c6ab-658bce62e44b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>1.0</td>\n",
       "      <td>FLMNE</td>\n",
       "      <td>The Faculté Libre de Médecines Naturelles et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12712</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Selden Edwards</td>\n",
       "      <td>Selden Edwards (born 1941) is an American wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Société de transport du Saguenay</td>\n",
       "      <td>Société de transport du Saguenay (STS) is the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9623</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Webber Independent School</td>\n",
       "      <td>The Webber Independent School (formerly Bury ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11471</th>\n",
       "      <td>3.0</td>\n",
       "      <td>T. R. Papa</td>\n",
       "      <td>Thiruthuraipoondi Radhakrishnan Pappa (Tamil:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                 1  \\\n",
       "2593   1.0                             FLMNE   \n",
       "12712  3.0                    Selden Edwards   \n",
       "1801   1.0  Société de transport du Saguenay   \n",
       "9623   2.0         Webber Independent School   \n",
       "11471  3.0                        T. R. Papa   \n",
       "\n",
       "                                                       2  \n",
       "2593    The Faculté Libre de Médecines Naturelles et ...  \n",
       "12712   Selden Edwards (born 1941) is an American wri...  \n",
       "1801    Société de transport du Saguenay (STS) is the...  \n",
       "9623    The Webber Independent School (formerly Bury ...  \n",
       "11471   Thiruthuraipoondi Radhakrishnan Pappa (Tamil:...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(5) #sample from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xIdmfSJsm4ZN"
   },
   "outputs": [],
   "source": [
    "train_label = pd.to_numeric(train_data.iloc[:,0]) #select labels (int) from train data\n",
    "train_text = train_data.iloc[:,1:3] #select article text from train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dbfQMlpGpJY1"
   },
   "outputs": [],
   "source": [
    "test_label = pd.to_numeric(test_data.iloc[:,0]) #select labels (int) from test data\n",
    "test_text = test_data.iloc[:,1:3] #select article text from train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqOIQiMFcCKk"
   },
   "source": [
    "#Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGd_NGTLql8R",
    "outputId": "c81af597-d31e-42c9-a01e-72453dd27a3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kornel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #vectorizer for article text data\n",
    "from nltk.corpus import stopwords #stopwords for desktop usage\n",
    "import nltk\n",
    "nltk.download('stopwords') #stopwords for collab notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0sdo8wL7CGFM"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), analyzer='word', ngram_range=(1, 1)) #vectorizer for words, removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8x0-IR01DRW6"
   },
   "outputs": [],
   "source": [
    "test_title = test_text.iloc[:,0] #select titles from test text\n",
    "test_desc = test_text.iloc[:,1]  #select descriptions from test text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yuKl7x3U33gu"
   },
   "outputs": [],
   "source": [
    "train_title = train_text.iloc[:,0] #select titles from train text\n",
    "train_desc = train_text.iloc[:,1]  #select descriptions from train text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "t_3wCcvAmo_N"
   },
   "outputs": [],
   "source": [
    "titles = pd.concat([test_title, train_title]) #concat titles for vectorazition\n",
    "descs = pd.concat([test_desc, train_desc]) #concat descriptions for vectorazition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SyFZpmsYEuLP"
   },
   "outputs": [],
   "source": [
    "titles = pd.DataFrame.sparse.from_spmatrix(vectorizer.fit_transform(titles)) #vectorizing test_title and adding it to a dataframe\n",
    "title_feature_names = np.asarray(vectorizer.get_feature_names()) #getting all feature names for test_title\n",
    "descs = pd.DataFrame.sparse.from_spmatrix(vectorizer.fit_transform(descs)) #vectorizing test_desc and adding it to a dataframe\n",
    "desc_feature_names = np.asarray(vectorizer.get_feature_names()) #getting all feature names for test_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qKD2R761ndPh"
   },
   "outputs": [],
   "source": [
    "test_title = titles[0:len(test_title.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7H4Pac1xoYgu"
   },
   "outputs": [],
   "source": [
    "test_title = test_title.loc[:, test_title.sum(axis=0) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XqEi2-fBhGtB",
    "outputId": "9f8a7b45-e0e2-4b58-a5d8-874a76289736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   88      101     177     184     191     206     234     246     267     \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   269     ...  127477  127487  127516  127536  127567  127570  127654  \\\n",
      "0       0  ...       0       0       0       0       0       0       0   \n",
      "1       0  ...       0       0       0       0       0       0       0   \n",
      "2       0  ...       0       0       0       0       0       0       0   \n",
      "3       0  ...       0       0       0       0       0       0       0   \n",
      "4       0  ...       0       0       0       0       0       0       0   \n",
      "\n",
      "   127678  127921  128028  \n",
      "0       0       0       0  \n",
      "1       0       0       0  \n",
      "2       0       0       0  \n",
      "3       0       0       0  \n",
      "4       0       0       0  \n",
      "\n",
      "[5 rows x 6054 columns]\n",
      "['002' '05' '07' '09' '0verflow']\n"
     ]
    }
   ],
   "source": [
    "#First 5 rows and feature names obtained with the vectoritzer\n",
    "print(test_title[0:5])\n",
    "print(title_feature_names[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "z5txOGWsp_G_"
   },
   "outputs": [],
   "source": [
    "test_desc = descs.head(len(test_desc.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uJ-KYd0OxKuY"
   },
   "outputs": [],
   "source": [
    "test_desc = test_desc.loc[:, test_desc.sum(axis=0) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukBvNK_bpH-J",
    "outputId": "1fc901aa-4f52-41a7-a887-d910c0d06ce0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0       1       56      70      83      84      111     132     147     \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   154     ...  313582  313671  313731  314204  314499  315294  315478  \\\n",
      "0       0  ...       0       0       0       0       0       0       0   \n",
      "1       0  ...       0       0       0       0       0       0       0   \n",
      "2       0  ...       0       0       0       0       0       0       0   \n",
      "3       0  ...       0       0       0       0       0       0       0   \n",
      "4       0  ...       0       0       0       0       0       0       0   \n",
      "\n",
      "   315615  315709  315723  \n",
      "0       0       0       0  \n",
      "1       0       0       0  \n",
      "2       0       0       0  \n",
      "3       0       0       0  \n",
      "4       0       0       0  \n",
      "\n",
      "[5 rows x 34626 columns]\n"
     ]
    }
   ],
   "source": [
    "#First 5 rows and feature names obtained with the vectorizer\n",
    "print(test_desc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-54u7V4OFOnh"
   },
   "outputs": [],
   "source": [
    "train_title = titles.tail(len(test_title.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SsJ1HLPjycIQ"
   },
   "outputs": [],
   "source": [
    "train_title = train_title.loc[:, train_title.sum(axis=0) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXIH2FymkHOK",
    "outputId": "5363c733-c6fe-4add-c3b4-0a866c0e8190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        23      37      55      69      81      101     113     125     \\\n",
      "200000       0       0       0       0       0       0       0       0   \n",
      "200001       0       0       0       0       0       0       0       0   \n",
      "200002       0       0       0       0       0       0       0       0   \n",
      "200003       0       0       0       0       0       0       0       0   \n",
      "200004       0       0       0       0       0       0       0       0   \n",
      "\n",
      "        137     165     ...  127511  127516  127528  127536  127568  127570  \\\n",
      "200000       0       0  ...       0       0       0       0       0       0   \n",
      "200001       0       0  ...       0       0       0       0       0       0   \n",
      "200002       0       0  ...       0       0       0       0       0       0   \n",
      "200003       0       0  ...       0       0       0       0       0       0   \n",
      "200004       0       0  ...       0       0       0       0       0       0   \n",
      "\n",
      "        127572  127709  128021  128028  \n",
      "200000       0       0       0       0  \n",
      "200001       0       0       0       0  \n",
      "200002       0       0       0       0  \n",
      "200003       0       0       0       0  \n",
      "200004       0       0       0       0  \n",
      "\n",
      "[5 rows x 5933 columns]\n"
     ]
    }
   ],
   "source": [
    "#First 5 rows and feature names obtained with the vectoritzer\n",
    "print(train_title[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "SKbN2KbbsUqd"
   },
   "outputs": [],
   "source": [
    "train_desc = descs.tail(len(test_desc.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BFNdC3fUza2X"
   },
   "outputs": [],
   "source": [
    "train_desc = train_desc.loc[:, train_desc.sum(axis=0) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmOXEY0fq3Pu",
    "outputId": "ece29904-f09c-4445-a071-6bfab1cf2fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       83      111     132     147     154     169     181     \\\n",
      "200000       0       0       0       0       0       0       0       0   \n",
      "200001       0       0       0       0       0       0       0       0   \n",
      "200002       0       0       0       0       0       0       0       0   \n",
      "200003       0       0       0       0       0       0       0       0   \n",
      "200004       0       0       0       0       0       0       0       0   \n",
      "\n",
      "        192     214     ...  313673  314371  314605  314629  314810  315442  \\\n",
      "200000       0       0  ...       0       0       0       0       0       0   \n",
      "200001       0       0  ...       0       0       0       0       0       0   \n",
      "200002       0       0  ...       0       0       0       0       0       0   \n",
      "200003       0       0  ...       0       0       0       0       0       0   \n",
      "200004       0       0  ...       0       0       0       0       0       0   \n",
      "\n",
      "        315478  315556  315560  315718  \n",
      "200000       0       0       0       0  \n",
      "200001       0       0       0       0  \n",
      "200002       0       0       0       0  \n",
      "200003       0       0       0       0  \n",
      "200004       0       0       0       0  \n",
      "\n",
      "[5 rows x 27315 columns]\n"
     ]
    }
   ],
   "source": [
    "#First 5 rows and feature names obtained with the vectoritzer\n",
    "print(train_desc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "omfbCxvr-aJl"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix #for min-max scaling sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "_B3DpLPb7Dku"
   },
   "outputs": [],
   "source": [
    "def normalize(df): #function for min-max scaling of dataframes\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = csr_matrix(df[feature_name]).max()\n",
    "        min_value = csr_matrix(df[feature_name]).min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / max((max_value - min_value), 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "xofqUiCj51N2"
   },
   "outputs": [],
   "source": [
    "test_title = normalize(test_title) #min-max scale test_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZtMnnUptxIn",
    "outputId": "f3878749-cb09-4584-ee1b-b6791e7888df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   88      101     177     184     191     206     234     246     267     \\\n",
      "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   269     ...  127477  127487  127516  127536  127567  127570  127654  \\\n",
      "0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   127678  127921  128028  \n",
      "0     0.0     0.0     0.0  \n",
      "1     0.0     0.0     0.0  \n",
      "2     0.0     0.0     0.0  \n",
      "3     0.0     0.0     0.0  \n",
      "4     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 6054 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_title[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "4v9lEKB951N2"
   },
   "outputs": [],
   "source": [
    "test_desc = normalize(test_desc) #min-max scale test_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cH74B7tUtxgF",
    "outputId": "a009e5c4-678e-4b7a-8738-191925be88dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0       1       56      70      83      84      111     132     147     \\\n",
      "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   154     ...  313582  313671  313731  314204  314499  315294  315478  \\\n",
      "0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   315615  315709  315723  \n",
      "0     0.0     0.0     0.0  \n",
      "1     0.0     0.0     0.0  \n",
      "2     0.0     0.0     0.0  \n",
      "3     0.0     0.0     0.0  \n",
      "4     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 34626 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_desc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "seP8jG3CB-qB"
   },
   "outputs": [],
   "source": [
    "train_title = normalize(train_title) #min-max scale train_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z37ue-AbtxyD",
    "outputId": "e7636be3-6465-4020-b23e-0c2449a34a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        23      37      55      69      81      101     113     125     \\\n",
      "200000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200001     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200002     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200003     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200004     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "        137     165     ...  127511  127516  127528  127536  127568  127570  \\\n",
      "200000     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200001     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200002     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200003     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200004     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "        127572  127709  128021  128028  \n",
      "200000     0.0     0.0     0.0     0.0  \n",
      "200001     0.0     0.0     0.0     0.0  \n",
      "200002     0.0     0.0     0.0     0.0  \n",
      "200003     0.0     0.0     0.0     0.0  \n",
      "200004     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 5933 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_title[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "t7My4oYrSmLv"
   },
   "outputs": [],
   "source": [
    "train_desc = normalize(train_desc) #min-max scale train_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAJvee20tyUd",
    "outputId": "3cec0140-014d-4fa8-9b7c-579f0b00a625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       83      111     132     147     154     169     181     \\\n",
      "200000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200001     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200002     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200003     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200004     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "        192     214     ...  313673  314371  314605  314629  314810  315442  \\\n",
      "200000     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200001     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200002     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200003     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "200004     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "        315478  315556  315560  315718  \n",
      "200000     0.0     0.0     0.0     0.0  \n",
      "200001     0.0     0.0     0.0     0.0  \n",
      "200002     0.0     0.0     0.0     0.0  \n",
      "200003     0.0     0.0     0.0     0.0  \n",
      "200004     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 27315 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_desc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_SyYggbJorJj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "_OYLgAiIe9wE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Conv1D, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ZBZxmZ1Te9uW"
   },
   "outputs": [],
   "source": [
    "input_shape = train_desc.head(1).shape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, 1, activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Conv1D(64, 1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 1, 32)             874112    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1, 64)             2112      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 885,189\n",
      "Trainable params: 885,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "patience=10\n",
    "early_stopping=EarlyStopping(patience=patience, verbose=1)\n",
    "checkpointer=ModelCheckpoint(filepath='model.hdf5', save_best_only=True, verbose=1)\n",
    "tb = TensorBoard(log_dir='logs', histogram_freq=1, write_graph=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.09 GiB for an array with shape (27315, 25000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-ff6d6d47a980>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnetwork_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_desc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         steps=steps_per_epoch)\n\u001b[0m\u001b[0;32m    553\u001b[0m     (x, y, sample_weights,\n\u001b[0;32m    554\u001b[0m      \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    519\u001b[0m       ]\n\u001b[0;32m    520\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5341\u001b[0m         \"\"\"\n\u001b[0;32m   5342\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5343\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5345\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mas_array\u001b[1;34m(self, transpose, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m    851\u001b[0m                     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m             \u001b[1;31m# The underlying data was copied within _interleave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m    880\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"object\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[0mitemmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.09 GiB for an array with shape (27315, 25000) and data type float64"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "network_history = model.fit(train_desc, train_label, batch_size=128, epochs=30, verbose=1, validation_split=0.2, callbacks=[early_stopping, checkpointer, tb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsQlbcyBklGw"
   },
   "source": [
    "Our **X** will be the sparse matrices and the feature names from the title and the description, and **Y** will be the labels provided in the csv file.\n",
    "\n",
    "Validation split is obtained later in the model.fit() function from training data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dataimport.ipynb másolata",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
